{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "6dUs6-GQkKhq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG5kuLj-kGWO",
        "outputId": "deb32da6-0d5d-413d-9956-7598830fd06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (example: Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a logistic regression model\n",
        "logistic_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "\n",
        "# Fit the model on the training data\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "6hxu6hyIqkcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (example: Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a decision tree classifier\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "mpyk2w-IqnaG",
        "outputId": "bdd28bd7-06c6-4f6e-a8d5-9aa684cfa41d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "hZ_0mkCYg_zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "fcjYCjnQhCBy",
        "outputId": "0d217e8a-7b68-416f-9242-ae74d02e7df4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-Nearest Neighbours (K-NN)"
      ],
      "metadata": {
        "id": "K9FVCGFmiwNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the UCI Heart Disease dataset\n",
        "\n",
        "dataset = pd.read_csv('/content/UCI Heart Disease.csv')\n",
        "\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "\n",
        "# preparing training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# scaling the train and test set\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# get the optimal value of K using GridSearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# set the range of k\n",
        "k = list(range(1,41))\n",
        "param_grid  = {'n_neighbors':k,'metric':['euclidean','minkowski']}\n",
        "grid = GridSearchCV(model, param_grid,scoring='accuracy', return_train_score=False)\n",
        "grid.fit(X_train,y_train)\n",
        "print(grid.best_params_)\n",
        "\n",
        "# finalizing the model with k=16\n",
        "KNN_classifier = KNeighborsClassifier(n_neighbors=16, metric='euclidean')\n",
        "# training the classifier\n",
        "KNN_classifier.fit(X_train,y_train)\n",
        "\n",
        "# test score\n",
        "print('Test score:')\n",
        "KNN_classifier.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI9weDD3i0jZ",
        "outputId": "bd232c4d-0d4e-4f94-8c75-2b10323a1fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metric': 'euclidean', 'n_neighbors': 16}\n",
            "Test score:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8360655737704918"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes"
      ],
      "metadata": {
        "id": "n5jEKiEgi1Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required library\n",
        "import pandas as pd\n",
        "\n",
        "# Reading the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vaibhav05cse/MLGB-Datasets/main/Iris.csv')\n",
        "\n",
        "# Defining input (X) and output (y) features\n",
        "X = data.iloc[:, 1:-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Creating training and test patterns\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, shuffle=True, random_state = 0)\n",
        "\n",
        "# input patterns\n",
        "X_train[:11]\n",
        "\n",
        "# Min-Max Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Defining the Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "\n",
        "# Training the SVM classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions with the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Combining the actual and predicted values\n",
        "pd.DataFrame(data={'Actual Labels': y_test, 'Predicted Labels': y_pred}).head()\n",
        "\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNfjKKNzi7qF",
        "outputId": "bd983481-d3e5-410f-e401-361518cea79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        11\n",
            "Iris-versicolor       0.93      1.00      0.96        13\n",
            " Iris-virginica       1.00      0.83      0.91         6\n",
            "\n",
            "       accuracy                           0.97        30\n",
            "      macro avg       0.98      0.94      0.96        30\n",
            "   weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Machine"
      ],
      "metadata": {
        "id": "k-ogUOxCi8nC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required library\n",
        "import pandas as pd\n",
        "\n",
        "# Reading the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/vaibhav05cse/MLGB-Datasets/main/diabetes.csv')\n",
        "\n",
        "# Defining input (X) and output (y) features\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Creating training and test patterns\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, shuffle=True, random_state = 0)\n",
        "\n",
        "# Feature scaling (z-standardization)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Defining the SVM classification model\n",
        "from sklearn.svm import SVC\n",
        "SVM_classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "\n",
        "# Training the SVM classifier\n",
        "SVM_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions with the test data\n",
        "y_pred = SVM_classifier.predict(X_test)\n",
        "\n",
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yi1rbyti_iQ",
        "outputId": "508a80cf-30cb-47d4-be91-41beb8b44652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88        78\n",
            "           1       0.78      0.66      0.71        38\n",
            "\n",
            "    accuracy                           0.83       116\n",
            "   macro avg       0.81      0.78      0.80       116\n",
            "weighted avg       0.82      0.83      0.82       116\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification  Evaluation Metrics"
      ],
      "metadata": {
        "id": "g9nY5dc0jACB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "iris_data = load_iris()\n",
        "X = iris_data.data\n",
        "y = iris_data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit a classification model\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')  # Macro-average precision\n",
        "recall = recall_score(y_test, y_pred, average='macro')  # Macro-average recall\n",
        "f1 = f1_score(y_test, y_pred, average='macro')  # Macro-average F1 score\n",
        "auc_roc = roc_auc_score(y_test, classifier.predict_proba(X_test), multi_class='ovr')  # AUC-ROC score\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"AUC-ROC Score:\", auc_roc)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR0qXfwBjEfs",
        "outputId": "26ec9794-0fb7-48a0-d902-dbf70a9c983f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "AUC-ROC Score: 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}